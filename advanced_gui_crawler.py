#!/usr/bin/env python3
"""
ê³ ê¸‰ GUI ì›¹ í¬ë¡¤ëŸ¬ - 2ë‹¨ê³„: ì‚¬ì´íŠ¸ í…œí”Œë¦¿ ì‹œìŠ¤í…œ
"""

import sys
import json
import re
from datetime import datetime
from PyQt5.QtWidgets import (QApplication, QMainWindow, QWidget, QVBoxLayout, 
                            QHBoxLayout, QLabel, QLineEdit, QPushButton, 
                            QTextEdit, QProgressBar, QComboBox, QGroupBox,
                            QMessageBox, QTabWidget, QTableWidget, QTableWidgetItem,
                            QCheckBox, QListWidget, QListWidgetItem, QSplitter)
from PyQt5.QtCore import QThread, pyqtSignal, Qt
from PyQt5.QtGui import QFont, QIcon
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin, urlparse
from fake_useragent import UserAgent
import time

class TemplateCrawler:
    """í…œí”Œë¦¿ ê¸°ë°˜ í¬ë¡¤ëŸ¬"""
    
    def __init__(self):
        self.templates = self.load_templates()
        
    def load_templates(self):
        """í…œí”Œë¦¿ íŒŒì¼ ë¡œë“œ"""
        try:
            with open('site_templates.json', 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            return {}
    
    def detect_site_type(self, url, soup):
        """ì‚¬ì´íŠ¸ ìœ í˜• ìë™ ê°ì§€"""
        # URL íŒ¨í„´ìœ¼ë¡œ ê°ì§€
        domain = urlparse(url).netloc.lower()
        
        if any(keyword in domain for keyword in ['shop', 'store', 'mall', 'market']):
            return 'shopping'
        elif any(keyword in domain for keyword in ['news', 'press', 'media']):
            return 'news'
        elif any(keyword in domain for keyword in ['blog', 'post', 'article']):
            return 'blog'
        elif any(keyword in domain for keyword in ['forum', 'community', 'board']):
            return 'forum'
        else:
            return 'general'
    
    def extract_with_template(self, soup, template_type):
        """í…œí”Œë¦¿ì„ ì‚¬ìš©í•œ ì •ë³´ ì¶”ì¶œ"""
        if template_type not in self.templates:
            template_type = 'general'
        
        template = self.templates[template_type]
        result = {}
        
        # ì„ íƒì ê¸°ë°˜ ì¶”ì¶œ
        for field, selectors in template['selectors'].items():
            for selector in selectors:
                try:
                    elements = soup.select(selector)
                    if elements:
                        if field in ['images']:
                            result[field] = []
                            for elem in elements[:10]:  # ìµœëŒ€ 10ê°œ
                                src = elem.get('src', '')
                                alt = elem.get('alt', '')
                                result[field].append({'src': src, 'alt': alt})
                        else:
                            texts = [elem.get_text(strip=True) for elem in elements]
                            result[field] = texts[0] if len(texts) == 1 else texts
                        break
                except Exception:
                    continue
        
        # íŒ¨í„´ ê¸°ë°˜ ì¶”ì¶œ
        if 'patterns' in template:
            text_content = soup.get_text()
            for field, patterns in template['patterns'].items():
                for pattern in patterns:
                    matches = re.findall(pattern, text_content)
                    if matches:
                        result[f'{field}_matches'] = matches[:5]  # ìµœëŒ€ 5ê°œ
                        break
        
        return result

class AdvancedCrawlerThread(QThread):
    """ê³ ê¸‰ í¬ë¡¤ë§ ì‘ì—…ì„ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰"""
    progress_signal = pyqtSignal(str)
    finished_signal = pyqtSignal(dict)
    error_signal = pyqtSignal(str)
    
    def __init__(self, url, template_type="auto", custom_selectors=None):
        super().__init__()
        self.url = url
        self.template_type = template_type
        self.custom_selectors = custom_selectors or {}
        self.is_running = True
        self.crawler = TemplateCrawler()
        
    def run(self):
        try:
            self.progress_signal.emit("í¬ë¡¤ë§ ì‹œì‘...")
            result = self.advanced_crawl()
            
            if self.is_running:
                self.finished_signal.emit(result)
                
        except Exception as e:
            self.error_signal.emit(str(e))
    
    def advanced_crawl(self):
        """ê³ ê¸‰ í¬ë¡¤ë§"""
        self.progress_signal.emit("í˜ì´ì§€ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
        
        # User-Agent ì„¤ì •
        ua = UserAgent()
        headers = {
            'User-Agent': ua.random,
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'ko-KR,ko;q=0.8,en-US;q=0.5,en;q=0.3',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
        }
        
        # í˜ì´ì§€ ê°€ì ¸ì˜¤ê¸°
        response = requests.get(self.url, headers=headers, timeout=10)
        response.raise_for_status()
        
        self.progress_signal.emit("í˜ì´ì§€ íŒŒì‹± ì¤‘...")
        
        # BeautifulSoupìœ¼ë¡œ íŒŒì‹±
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # ê¸°ë³¸ ì •ë³´
        data = {
            'url': self.url,
            'timestamp': datetime.now().isoformat(),
            'site_type': 'unknown',
            'extracted_data': {},
            'basic_info': {}
        }
        
        # ì‚¬ì´íŠ¸ ìœ í˜• ê°ì§€
        if self.template_type == "auto":
            detected_type = self.crawler.detect_site_type(self.url, soup)
            data['site_type'] = detected_type
        else:
            data['site_type'] = self.template_type
        
        self.progress_signal.emit(f"ì‚¬ì´íŠ¸ ìœ í˜•: {data['site_type']}")
        
        # í…œí”Œë¦¿ ê¸°ë°˜ ì¶”ì¶œ
        self.progress_signal.emit("í…œí”Œë¦¿ ê¸°ë°˜ ì •ë³´ ì¶”ì¶œ ì¤‘...")
        template_data = self.crawler.extract_with_template(soup, data['site_type'])
        data['extracted_data'] = template_data
        
        # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
        self.progress_signal.emit("ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ ì¤‘...")
        basic_info = self.extract_basic_info(soup)
        data['basic_info'] = basic_info
        
        # ì»¤ìŠ¤í…€ ì„ íƒì ì ìš©
        if self.custom_selectors:
            self.progress_signal.emit("ì»¤ìŠ¤í…€ ì„ íƒì ì ìš© ì¤‘...")
            custom_data = self.extract_with_custom_selectors(soup)
            data['custom_data'] = custom_data
        
        self.progress_signal.emit("í¬ë¡¤ë§ ì™„ë£Œ!")
        return data
    
    def extract_basic_info(self, soup):
        """ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ"""
        info = {
            'title': '',
            'description': '',
            'keywords': [],
            'images': [],
            'links': [],
            'text_content': '',
            'headers': {},
            'meta_tags': {}
        }
        
        # ì œëª©
        title_tag = soup.find('title')
        if title_tag:
            info['title'] = title_tag.get_text(strip=True)
        
        # ë©”íƒ€ íƒœê·¸
        for meta in soup.find_all('meta'):
            name = meta.get('name', '').lower()
            content = meta.get('content', '')
            
            if name == 'description':
                info['description'] = content
            elif name == 'keywords':
                info['keywords'] = [kw.strip() for kw in content.split(',')]
            else:
                info['meta_tags'][name] = content
        
        # í—¤ë”
        for i in range(1, 7):
            headers = soup.find_all(f'h{i}')
            info['headers'][f'h{i}'] = [h.get_text(strip=True) for h in headers]
        
        # ì´ë¯¸ì§€
        for img in soup.find_all('img', src=True):
            src = img['src']
            alt = img.get('alt', '')
            info['images'].append({
                'src': urljoin(self.url, src),
                'alt': alt
            })
        
        # ë§í¬
        base_domain = urlparse(self.url).netloc
        for link in soup.find_all('a', href=True):
            href = link['href']
            absolute_url = urljoin(self.url, href)
            link_domain = urlparse(absolute_url).netloc
            
            if link_domain == base_domain:
                info['links'].append({
                    'url': absolute_url,
                    'text': link.get_text(strip=True),
                    'title': link.get('title', '')
                })
        
        # í…ìŠ¤íŠ¸
        for script in soup(["script", "style", "nav", "footer"]):
            script.decompose()
        
        text_content = soup.get_text(separator=' ', strip=True)
        info['text_content'] = text_content[:1000] + "..." if len(text_content) > 1000 else text_content
        
        return info
    
    def extract_with_custom_selectors(self, soup):
        """ì»¤ìŠ¤í…€ ì„ íƒìë¡œ ì¶”ì¶œ"""
        custom_data = {}
        
        for field, selector in self.custom_selectors.items():
            try:
                elements = soup.select(selector)
                if elements:
                    texts = [elem.get_text(strip=True) for elem in elements]
                    custom_data[field] = texts[0] if len(texts) == 1 else texts
            except Exception:
                continue
        
        return custom_data
    
    def stop(self):
        """í¬ë¡¤ë§ ì¤‘ì§€"""
        self.is_running = False

class AdvancedWebCrawlerGUI(QMainWindow):
    """ê³ ê¸‰ ì›¹ í¬ë¡¤ëŸ¬ GUI"""
    
    def __init__(self):
        super().__init__()
        self.crawler_thread = None
        self.template_crawler = TemplateCrawler()
        self.init_ui()
        
    def init_ui(self):
        """UI ì´ˆê¸°í™”"""
        self.setWindowTitle("ğŸŒ ê³ ê¸‰ ì›¹ í¬ë¡¤ëŸ¬ GUI")
        self.setGeometry(100, 100, 1400, 900)
        
        # ì¤‘ì•™ ìœ„ì ¯
        central_widget = QWidget()
        self.setCentralWidget(central_widget)
        
        # ë©”ì¸ ë ˆì´ì•„ì›ƒ
        layout = QVBoxLayout(central_widget)
        
        # ì œëª©
        title_label = QLabel("ê³ ê¸‰ ì›¹ í¬ë¡¤ëŸ¬ GUI")
        title_label.setFont(QFont("Arial", 16, QFont.Bold))
        title_label.setAlignment(Qt.AlignCenter)
        layout.addWidget(title_label)
        
        # URL ì…ë ¥ ê·¸ë£¹
        url_group = QGroupBox("URL ì…ë ¥")
        url_layout = QHBoxLayout(url_group)
        
        url_label = QLabel("URL:")
        self.url_input = QLineEdit()
        self.url_input.setPlaceholderText("https://example.com")
        
        self.template_combo = QComboBox()
        self.template_combo.addItems(["ìë™ ê°ì§€", "ì‡¼í•‘ëª°", "ë‰´ìŠ¤ ì‚¬ì´íŠ¸", "ë¸”ë¡œê·¸", "í¬ëŸ¼/ì»¤ë®¤ë‹ˆí‹°", "ì¼ë°˜ ì›¹ì‚¬ì´íŠ¸"])
        
        self.crawl_button = QPushButton("í¬ë¡¤ë§ ì‹œì‘")
        self.crawl_button.clicked.connect(self.start_crawling)
        
        url_layout.addWidget(url_label)
        url_layout.addWidget(self.url_input)
        url_layout.addWidget(self.template_combo)
        url_layout.addWidget(self.crawl_button)
        
        layout.addWidget(url_group)
        
        # ì»¤ìŠ¤í…€ ì„ íƒì ê·¸ë£¹
        custom_group = QGroupBox("ì»¤ìŠ¤í…€ ì„ íƒì")
        custom_layout = QHBoxLayout(custom_group)
        
        custom_label = QLabel("í•„ë“œëª…:")
        self.custom_field_input = QLineEdit()
        self.custom_field_input.setPlaceholderText("ì˜ˆ: price, author")
        
        selector_label = QLabel("CSS ì„ íƒì:")
        self.custom_selector_input = QLineEdit()
        self.custom_selector_input.setPlaceholderText("ì˜ˆ: .price, #author")
        
        add_selector_button = QPushButton("ì¶”ê°€")
        add_selector_button.clicked.connect(self.add_custom_selector)
        
        custom_layout.addWidget(custom_label)
        custom_layout.addWidget(self.custom_field_input)
        custom_layout.addWidget(selector_label)
        custom_layout.addWidget(self.custom_selector_input)
        custom_layout.addWidget(add_selector_button)
        
        layout.addWidget(custom_group)
        
        # ì»¤ìŠ¤í…€ ì„ íƒì ëª©ë¡
        self.custom_selectors_list = QListWidget()
        layout.addWidget(QLabel("ì¶”ê°€ëœ ì»¤ìŠ¤í…€ ì„ íƒì:"))
        layout.addWidget(self.custom_selectors_list)
        
        # ì§„í–‰ë¥  í‘œì‹œ
        self.progress_bar = QProgressBar()
        self.progress_bar.setVisible(False)
        layout.addWidget(self.progress_bar)
        
        # ìƒíƒœ í‘œì‹œ
        self.status_label = QLabel("ëŒ€ê¸° ì¤‘...")
        layout.addWidget(self.status_label)
        
        # íƒ­ ìœ„ì ¯
        self.tab_widget = QTabWidget()
        layout.addWidget(self.tab_widget)
        
        # ê²°ê³¼ íƒ­
        self.result_text = QTextEdit()
        self.result_text.setReadOnly(True)
        self.tab_widget.addTab(self.result_text, "ì „ì²´ ê²°ê³¼")
        
        # í…œí”Œë¦¿ ê²°ê³¼ íƒ­
        self.template_result_text = QTextEdit()
        self.template_result_text.setReadOnly(True)
        self.tab_widget.addTab(self.template_result_text, "í…œí”Œë¦¿ ê²°ê³¼")
        
        # ìš”ì•½ íƒ­
        self.summary_table = QTableWidget()
        self.tab_widget.addTab(self.summary_table, "ìš”ì•½ ì •ë³´")
        
        # ë²„íŠ¼ ê·¸ë£¹
        button_layout = QHBoxLayout()
        
        self.save_button = QPushButton("ê²°ê³¼ ì €ì¥")
        self.save_button.clicked.connect(self.save_results)
        self.save_button.setEnabled(False)
        
        self.clear_button = QPushButton("ì´ˆê¸°í™”")
        self.clear_button.clicked.connect(self.clear_results)
        
        button_layout.addWidget(self.save_button)
        button_layout.addWidget(self.clear_button)
        button_layout.addStretch()
        
        layout.addLayout(button_layout)
        
        # ê²°ê³¼ ë°ì´í„° ì €ì¥
        self.crawl_result = None
        self.custom_selectors = {}
        
    def add_custom_selector(self):
        """ì»¤ìŠ¤í…€ ì„ íƒì ì¶”ê°€"""
        field = self.custom_field_input.text().strip()
        selector = self.custom_selector_input.text().strip()
        
        if not field or not selector:
            QMessageBox.warning(self, "ê²½ê³ ", "í•„ë“œëª…ê³¼ ì„ íƒìë¥¼ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return
        
        self.custom_selectors[field] = selector
        
        # ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
        item_text = f"{field}: {selector}"
        item = QListWidgetItem(item_text)
        self.custom_selectors_list.addItem(item)
        
        # ì…ë ¥ í•„ë“œ ì´ˆê¸°í™”
        self.custom_field_input.clear()
        self.custom_selector_input.clear()
        
    def start_crawling(self):
        """í¬ë¡¤ë§ ì‹œì‘"""
        url = self.url_input.text().strip()
        
        if not url:
            QMessageBox.warning(self, "ê²½ê³ ", "URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return
        
        if not url.startswith(('http://', 'https://')):
            url = 'https://' + url
            self.url_input.setText(url)
        
        # UI ìƒíƒœ ë³€ê²½
        self.crawl_button.setEnabled(False)
        self.crawl_button.setText("í¬ë¡¤ë§ ì¤‘...")
        self.progress_bar.setVisible(True)
        self.progress_bar.setRange(0, 0)
        self.status_label.setText("í¬ë¡¤ë§ ì¤€ë¹„ ì¤‘...")
        
        # í…œí”Œë¦¿ íƒ€ì… ê²°ì •
        template_map = {
            "ìë™ ê°ì§€": "auto",
            "ì‡¼í•‘ëª°": "shopping",
            "ë‰´ìŠ¤ ì‚¬ì´íŠ¸": "news",
            "ë¸”ë¡œê·¸": "blog",
            "í¬ëŸ¼/ì»¤ë®¤ë‹ˆí‹°": "forum",
            "ì¼ë°˜ ì›¹ì‚¬ì´íŠ¸": "general"
        }
        template_type = template_map[self.template_combo.currentText()]
        
        # í¬ë¡¤ë§ ìŠ¤ë ˆë“œ ì‹œì‘
        self.crawler_thread = AdvancedCrawlerThread(url, template_type, self.custom_selectors)
        self.crawler_thread.progress_signal.connect(self.update_progress)
        self.crawler_thread.finished_signal.connect(self.crawling_finished)
        self.crawler_thread.error_signal.connect(self.crawling_error)
        self.crawler_thread.start()
        
    def update_progress(self, message):
        """ì§„í–‰ë¥  ì—…ë°ì´íŠ¸"""
        self.status_label.setText(message)
        
    def crawling_finished(self, result):
        """í¬ë¡¤ë§ ì™„ë£Œ"""
        self.crawl_result = result
        
        # UI ìƒíƒœ ë³µì›
        self.crawl_button.setEnabled(True)
        self.crawl_button.setText("í¬ë¡¤ë§ ì‹œì‘")
        self.progress_bar.setVisible(False)
        self.status_label.setText("í¬ë¡¤ë§ ì™„ë£Œ!")
        
        # ê²°ê³¼ í‘œì‹œ
        self.display_results(result)
        
        # ì €ì¥ ë²„íŠ¼ í™œì„±í™”
        self.save_button.setEnabled(True)
        
    def crawling_error(self, error_message):
        """í¬ë¡¤ë§ ì—ëŸ¬"""
        self.crawl_button.setEnabled(True)
        self.crawl_button.setText("í¬ë¡¤ë§ ì‹œì‘")
        self.progress_bar.setVisible(False)
        self.status_label.setText("í¬ë¡¤ë§ ì‹¤íŒ¨!")
        
        QMessageBox.critical(self, "ì—ëŸ¬", f"í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤:\n{error_message}")
        
    def display_results(self, result):
        """ê²°ê³¼ í‘œì‹œ"""
        # ì „ì²´ ê²°ê³¼ í‘œì‹œ
        self.result_text.setText(json.dumps(result, ensure_ascii=False, indent=2))
        
        # í…œí”Œë¦¿ ê²°ê³¼ í‘œì‹œ
        template_data = result.get('extracted_data', {})
        self.template_result_text.setText(json.dumps(template_data, ensure_ascii=False, indent=2))
        
        # ìš”ì•½ ì •ë³´ í‘œì‹œ
        self.display_summary(result)
        
    def display_summary(self, result):
        """ìš”ì•½ ì •ë³´ í‘œì‹œ"""
        self.summary_table.setRowCount(10)
        self.summary_table.setColumnCount(2)
        self.summary_table.setHorizontalHeaderLabels(["í•­ëª©", "ê°’"])
        
        basic_info = result.get('basic_info', {})
        extracted_data = result.get('extracted_data', {})
        
        summary_data = [
            ("URL", result.get('url', '')),
            ("ì‚¬ì´íŠ¸ ìœ í˜•", result.get('site_type', '')),
            ("ì œëª©", basic_info.get('title', '')),
            ("ì„¤ëª…", basic_info.get('description', '')[:100] + "..." if len(basic_info.get('description', '')) > 100 else basic_info.get('description', '')),
            ("ì´ë¯¸ì§€ ìˆ˜", str(len(basic_info.get('images', [])))),
            ("ë§í¬ ìˆ˜", str(len(basic_info.get('links', [])))),
            ("ì¶”ì¶œëœ í•„ë“œ ìˆ˜", str(len(extracted_data))),
            ("ì»¤ìŠ¤í…€ í•„ë“œ ìˆ˜", str(len(result.get('custom_data', {})))),
            ("í¬ë¡¤ë§ ì‹œê°„", result.get('timestamp', '')),
            ("ìƒíƒœ", "ì™„ë£Œ")
        ]
        
        for i, (key, value) in enumerate(summary_data):
            self.summary_table.setItem(i, 0, QTableWidgetItem(key))
            self.summary_table.setItem(i, 1, QTableWidgetItem(value))
        
        self.summary_table.resizeColumnsToContents()
        
    def save_results(self):
        """ê²°ê³¼ ì €ì¥"""
        if not self.crawl_result:
            return
            
        filename = f"advanced_crawl_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(self.crawl_result, f, ensure_ascii=False, indent=2)
            
            QMessageBox.information(self, "ì„±ê³µ", f"ê²°ê³¼ê°€ {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            QMessageBox.critical(self, "ì—ëŸ¬", f"ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤:\n{str(e)}")
            
    def clear_results(self):
        """ê²°ê³¼ ì´ˆê¸°í™”"""
        self.result_text.clear()
        self.template_result_text.clear()
        self.summary_table.setRowCount(0)
        self.custom_selectors_list.clear()
        self.crawl_result = None
        self.custom_selectors = {}
        self.save_button.setEnabled(False)
        self.status_label.setText("ëŒ€ê¸° ì¤‘...")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    app = QApplication(sys.argv)
    app.setStyle('Fusion')
    
    window = AdvancedWebCrawlerGUI()
    window.show()
    
    sys.exit(app.exec_())

if __name__ == '__main__':
    main()
